###################################################################################
Gradient Descent
###################################################################################

.. note::
	* Local linear approximation information captured by gradient.
	* Local quadratic approximation information captured by Hessian.

***********************************************************************************
Nature of Stationary Point
***********************************************************************************
.. note::
	* Understanding the nature of local stationary point (maxima/minima/saddle point) with the help of Hessian.

***********************************************************************************
Learning-Rate Schedule
***********************************************************************************
.. note::
	* With fixed learning rate - takes infinitely many steps to reach the minimum

***********************************************************************************
Momentum
***********************************************************************************
.. note::
	* Normal Momentum
	* Nesterov Momentum

***********************************************************************************
Adaptive Learning Rate
***********************************************************************************
.. note::
	* RMSProp
	* Adam

***********************************************************************************
Managing Vanishing/Exploding Gradients
***********************************************************************************
.. note::
	* Input data normalisation
	* Weight normalisation: Batch Normalisation
	* Weight normalisation: Layer Normalisation
